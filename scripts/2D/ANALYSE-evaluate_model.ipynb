{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48c4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "from torch import nn\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipnet import data\n",
    "from pipnet import model\n",
    "from pipnet import utils\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909326be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = \"PIPNet_2022_11_15_2_layers\"\n",
    "\n",
    "in_dir = f\"../../data/2D/{mod}/\"\n",
    "fig_dir = f\"../../figures/2D/{mod}/\"\n",
    "\n",
    "#batch_size = 16\n",
    "batch_size = 4\n",
    "#n_batch = 64\n",
    "n_batch = 4\n",
    "#n_show = 64\n",
    "n_show = 4\n",
    "\n",
    "epoch = 250\n",
    "eval_all_steps = False\n",
    "\n",
    "eval_peaks = True\n",
    "n_peaks = np.arange(5) + 1\n",
    "\n",
    "eval_wr = True\n",
    "wrs = [\"wr1\", \"wr2\", \"wr1+wr2\"]\n",
    "\n",
    "eval_mas_high = True\n",
    "high_mas = [60000., 70000., 80000., 90000., 100000.]\n",
    "\n",
    "eval_mas_low = True\n",
    "low_mas = [50000., 60000., 70000., 80000., 90000.]\n",
    "\n",
    "eval_nw = True\n",
    "nw_max = 16\n",
    "\n",
    "eval_noise = True\n",
    "noise_levels = [0., 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2]\n",
    "\n",
    "eval_shift_noise = True\n",
    "shift_noise_levels = [0., 10., 20., 30., 40., 50., 60., 70., 80., 90., 100.]\n",
    "\n",
    "eval_lw_noise = True\n",
    "lw_noise_levels = [0., 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "eval_shift = True\n",
    "shift_values = [True, False]\n",
    "shift_labels = [\"Shift\", \"No shift\"]\n",
    "\n",
    "eval_constant = True\n",
    "\n",
    "iso_pars = dict(\n",
    "    td = 128,\n",
    "    Fs = 3_200,\n",
    "    nmin = 1,\n",
    "    nmax = 5,\n",
    "    freq_range = [500., 2700.],\n",
    "    gmin = 1,\n",
    "    gmax = 1,\n",
    "    spread = 5.,\n",
    "    lw_range = [[5e1, 2e2], [1e2, 5e2], [1e2, 1e3]],\n",
    "    lw_probs = [0.7, 0.2, 0.1],\n",
    "    int_range = [0.5, 1.], # Intensity\n",
    "    phase = 0.,\n",
    "    debug = False,\n",
    ")\n",
    "\n",
    "mas_pars = dict(\n",
    "    nw = 12,\n",
    "    mas_w_range = [50_000., 100_000.],\n",
    "    random_mas = True,\n",
    "    mas_phase_p = 0.5,\n",
    "    mas_phase_scale = 0.05,\n",
    "    \n",
    "    # First-order MAS-dependent parameters\n",
    "    mas1_lw_range = [[1e7, 5e7], [5e7, 1e8]],\n",
    "    mas1_lw_probs = [0.8, 0.2],\n",
    "    mas1_m_range = [[0., 0.], [0., 1e4], [1e4, 5e4]],\n",
    "    mas1_m_probs = [0.1, 0.1, 0.8],\n",
    "    mas1_s_range = [[-1e7, 1e7]],\n",
    "    mas1_s_probs = [1.],\n",
    "\n",
    "    # Second-order MAS-dependent parameters\n",
    "    mas2_prob = 1.,\n",
    "    mas2_lw_range = [[0., 0.], [1e11, 5e11]],\n",
    "    mas2_lw_probs = [0.5, 0.5],\n",
    "    mas2_m_range = [[0., 0.], [1e8, 5e8]],\n",
    "    mas2_m_probs = [0.8, 0.2],\n",
    "    mas2_s_range = [[0., 0.], [-2e10, 2e10]],\n",
    "    mas2_s_probs = [0.8, 0.2],\n",
    "    \n",
    "    # Other MAS-dependent parameters\n",
    "    non_mas_p = 0.5,\n",
    "    non_mas_m_trends = [\"constant\", \"increase\", \"decrease\"],\n",
    "    non_mas_m_probs = [0.34, 0.33, 0.33],\n",
    "    non_mas_m_range = [0., 1.],\n",
    "    \n",
    "    int_decrease_p = 0.1,\n",
    "    int_decrease_scale =[0.3, 0.7],\n",
    "    debug = False,\n",
    ")\n",
    "\n",
    "with open(f\"{in_dir}data_pars.json\", \"r\") as F:\n",
    "    data_pars = json.load(F)\n",
    "\n",
    "data_pars[\"iso_pars\"] = iso_pars\n",
    "data_pars[\"mas_pars\"] = mas_pars\n",
    "data_pars[\"noise\"] = 0.\n",
    "data_pars[\"mas_l_noise\"] = 0.05\n",
    "data_pars[\"mas_s_noise\"] = 25.\n",
    "data_pars[\"gen_mas_shifts\"] = False\n",
    "\n",
    "loss_pars1 = dict(\n",
    "    trg_fuzz = 0.,\n",
    "    trg_fuzz_len = 0,\n",
    "    ndim = 1,\n",
    "    exp = 1.0,\n",
    "    offset = 1.0,\n",
    "    factor = 0.0,\n",
    "    int_w = 1.0,\n",
    "    int_exp = 1.0,\n",
    "    return_components = True,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "loss_pars2 = dict(\n",
    "    trg_fuzz = 0.,\n",
    "    trg_fuzz_len = 0,\n",
    "    ndim = 1,\n",
    "    exp = 2.0,\n",
    "    offset = 1.0,\n",
    "    factor = 0.0,\n",
    "    int_w = 1.0,\n",
    "    int_exp = 2.0,\n",
    "    return_components = True,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "loss1 = model.PIPLoss(**loss_pars1)\n",
    "loss2 = model.PIPLoss(**loss_pars2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2050d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(in_dir):\n",
    "    raise ValueError(f\"Unknown model: {mod}\")\n",
    "    \n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)\n",
    "\n",
    "fdir = fig_dir + \"evaluation/\"\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.mkdir(fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1221ecf-ebe7-4be1-9ff7-54504639231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(in_dir + \"model_pars.json\", \"r\") as F:\n",
    "    model_pars = json.load(F)\n",
    "model_pars[\"noise\"] = 0.\n",
    "model_pars[\"return_all_layers\"] = eval_all_steps\n",
    "\n",
    "net = model.ConvLSTMEnsemble(**model_pars)\n",
    "net.load_state_dict(torch.load(in_dir + f\"epoch_{epoch}_network\", map_location=device))\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb6e71c-c4f8-491f-afa9-40854233dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cos_sim(y1, y2):\n",
    "    \n",
    "    sim = nn.CosineSimilarity(dim=-1)\n",
    "    \n",
    "    return torch.mean(sim(y1, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b0be80-8ce8-4d78-a423-99e77934f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(x, iso_maes, int_maes, iso_mses, cos_sims, norm=False, xlog=False, xticks=None, xticklabels=None, xlabel=\"x\", show=True, save=None):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax3 = fig.add_subplot(2,2,3)\n",
    "    ax4 = fig.add_subplot(2,2,4)\n",
    "    \n",
    "    ax1.plot(x, iso_maes, \".\")\n",
    "    ax2.plot(x, int_maes, \".\")\n",
    "    ax3.plot(x, iso_mses, \".\")\n",
    "    ax4.plot(x, cos_sims, \".\")\n",
    "    \n",
    "    if norm:\n",
    "        ax1.plot(x, iso_maes / x, \".\")\n",
    "        ax2.plot(x, int_maes / x, \".\")\n",
    "        ax3.plot(x, iso_mses / x, \".\")\n",
    "        ax4.plot(x, cos_sims, \".\")\n",
    "    \n",
    "    ax1.set_ylim(0., 1.1*np.max(iso_maes))\n",
    "    ax2.set_ylim(0., 1.1*np.max(int_maes))\n",
    "    ax3.set_ylim(0., 1.1*np.max(iso_mses))\n",
    "    ax4.set_ylim(0., 1.)\n",
    "\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    ax3.set_xlabel(xlabel)\n",
    "    ax4.set_xlabel(xlabel)\n",
    "    \n",
    "    if xticks is not None:\n",
    "        ax1.set_xticks(xticks)\n",
    "        ax2.set_xticks(xticks)\n",
    "        ax3.set_xticks(xticks)\n",
    "        ax4.set_xticks(xticks)\n",
    "        if xticklabels is not None:\n",
    "            ax1.set_xticklabels(xticklabels)\n",
    "            ax2.set_xticklabels(xticklabels)\n",
    "            ax3.set_xticklabels(xticklabels)\n",
    "            ax4.set_xticklabels(xticklabels)\n",
    "    \n",
    "    ax1.set_ylabel(\"Spectrum MAE\")\n",
    "    ax2.set_ylabel(\"Integral MAE\")\n",
    "    ax3.set_ylabel(\"Spectrum MSE\")\n",
    "    ax4.set_ylabel(\"Cosine similarity\")\n",
    "    \n",
    "    if norm:\n",
    "        ax1.legend([\"Absolute\", \"Normalised\"])\n",
    "        ax2.legend([\"Absolute\", \"Normalised\"])\n",
    "        ax3.legend([\"Absolute\", \"Normalised\"])\n",
    "        ax4.legend([\"Absolute\", \"Normalised\"])\n",
    "    \n",
    "    if xlog:\n",
    "        ax1.set_xscale(\"log\")\n",
    "        ax2.set_xscale(\"log\")\n",
    "        ax3.set_xscale(\"log\")\n",
    "        ax4.set_xscale(\"log\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save is not None:\n",
    "        fig.savefig(save)\n",
    "        \n",
    "        pp = \"\"\n",
    "        for xi, iso_mae, int_mae, iso_mse, cos_sim in zip(x, iso_maes, int_maes, iso_mses, cos_sims):\n",
    "            \n",
    "            if xticklabels is not None:\n",
    "                xi = xticklabels[xi].replace(\" \", \"_\")\n",
    "            \n",
    "            if norm:\n",
    "                pp += f\"{xi}\\t{iso_mae:.4e}\\t{int_mae:4e}\\t{iso_mse:.4e}\\t{cos_sim:.4e}\\t\"\n",
    "                pp += f\"{iso_mae/xi:.4e}\\t{int_mae/xi:4e}\\t{iso_mse/xi:.4e}\\t{cos_sim/xi:.4e}\\n\"\n",
    "            else:\n",
    "                pp += f\"{xi}\\t{iso_mae:.4e}\\t{int_mae:4e}\\t{iso_mse:.4e}\\t{cos_sim:.4e}\\n\"\n",
    "        \n",
    "        with open(\".\".join(save.split(\".\")[:-1]) + \".txt\", \"w\") as F:\n",
    "            F.write(pp)\n",
    "            \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86714c88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vary number of peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8b8ea4-7c66-4c84-b849-2449b6354a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 peaks\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating 2 peaks\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating 3 peaks\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating 4 peaks\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating 5 peaks\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n"
     ]
    }
   ],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_wr:\n",
    "    \n",
    "    for peaks in n_peaks:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"npeaks/{peaks}_peaks/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating {peaks} peaks\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        data_pars2[\"iso_pars\"][\"nmin\"] = peaks\n",
    "        data_pars2[\"iso_pars\"][\"nmax\"] = peaks\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        n_peaks,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        norm=True,\n",
    "        xlabel=\"Number of peaks\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_npeaks.pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80eb6a8-75b0-4912-a6dd-633fadb51a38",
   "metadata": {},
   "source": [
    "# w1 vs w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7678c832-82c1-4d6e-b732-c9c39d20c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating wr1\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating wr2\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelcordova/Desktop/Work/PIP/PIPNet/src/pipnet/utils.py:780: UserWarning: No contour levels were found within the data range.\n",
      "  ax1.contour(XX, YY, X[-(step+1), 0], levels=neg_levels, colors=\"C2\", linewidths=1.)\n",
      "/Users/manuelcordova/Desktop/Work/PIP/PIPNet/src/pipnet/utils.py:781: UserWarning: No contour levels were found within the data range.\n",
      "  ax2.contour(XX, YY, X[-(step+1), 0], levels=neg_levels, colors=\"C2\", linewidths=1.)\n",
      "/Users/manuelcordova/Desktop/Work/PIP/PIPNet/src/pipnet/utils.py:783: UserWarning: No contour levels were found within the data range.\n",
      "  ax3.contour(XX, YY, X[-(step+1), 0], levels=neg_levels, colors=\"C2\", linewidths=1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating wr1+wr2\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n"
     ]
    }
   ],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_peaks:\n",
    "    \n",
    "    for wr in wrs:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"w12/{wr.replace('+', '_')}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating {wr}\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        if \"wr1\" not in wr:\n",
    "            data_pars2[\"mas_pars\"][\"mas1_lw_range\"] = [[0., 0.]]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_lw_probs\"] = [1.]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_m_range\"] = [[0., 0.]]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_m_probs\"] = [1.]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_s_range\"] = [[0., 0.]]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_s_probs\"] = [1.]\n",
    "        \n",
    "        if \"wr2\" not in wr:\n",
    "            data_pars2[\"mas_pars\"][\"mas2_prob\"] = 0.\n",
    "        else:\n",
    "            data_pars2[\"mas_pars\"][\"mas2_lw_range\"] = [[1e11, 5e11]]\n",
    "            data_pars2[\"mas_pars\"][\"mas2_lw_probs\"] = [1.]\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        np.arange(len(wrs)),\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,xticks=np.arange(len(wrs)),\n",
    "        xticklabels=wrs,\n",
    "        xlabel=\"MAS dependence\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_wr12.pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8db257-db95-41e5-86a4-94bf6291cb7e",
   "metadata": {},
   "source": [
    "# Vary highest MAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "272c8270-90fa-45b1-9505-12c6554aee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating highest MAS rate 60 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 70 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 80 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 90 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 100 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n"
     ]
    }
   ],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_mas_high:\n",
    "    \n",
    "    for wr in high_mas:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"high_mas/{wr/1000.:.0f}_kHz/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating highest MAS rate {wr/1000.:.0f} kHz\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        wr0 = data_pars[\"mas_pars\"][\"mas_w_range\"]\n",
    "        wr1 = [wr0[0], wr]\n",
    "        nw0 = data_pars[\"mas_pars\"][\"nw\"]\n",
    "        nw1 = int(nw0 * (wr1[1]-wr1[0]) / (wr0[1]-wr0[0]))\n",
    "        nw1 = max(model_pars[\"batch_input\"]+1, nw1)\n",
    "        \n",
    "        data_pars2[\"mas_pars\"][\"mas_w_range\"] = wr1\n",
    "        data_pars2[\"mas_pars\"][\"nw\"] = nw1\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        high_mas,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Highest MAS rate\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_mas_high.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed6be4-4ae4-4adf-9987-100eefa29777",
   "metadata": {},
   "source": [
    "# Vary highest MAS, same number of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5d86d1-2c84-421b-bbbb-5e583b517199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating highest MAS rate 60 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 70 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 80 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n",
      "Generating highest MAS rate 90 kHz\n",
      "  Batch 1/4\n",
      "  Batch 2/4\n",
      "  Batch 3/4\n",
      "  Batch 4/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 39\u001b[0m     yi_pred, yi_std, yis_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m net\u001b[38;5;241m.\u001b[39mreturn_all_layers:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m net\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PIPNet/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Work/PIP/PIPNet/src/pipnet/model.py:542\u001b[0m, in \u001b[0;36mConvLSTMEnsemble.forward\u001b[0;34m(self, input_tensor, repeat_first_input)\u001b[0m\n\u001b[1;32m    540\u001b[0m         y, _, _ \u001b[38;5;241m=\u001b[39m net(X, repeat_first_input\u001b[38;5;241m=\u001b[39mrepeat_first_input)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m         y, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat_first_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_first_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     ys\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39munsqueeze(y\u001b[38;5;241m.\u001b[39mclone(), \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    545\u001b[0m ys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(ys, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PIPNet/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Work/PIP/PIPNet/src/pipnet/model.py:393\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state, repeat_first_input)\u001b[0m\n\u001b[1;32m    390\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_act(output)\n\u001b[1;32m    391\u001b[0m         output_list\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m--> 393\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m cur_layer_input \u001b[38;5;241m=\u001b[39m layer_output\n\u001b[1;32m    396\u001b[0m layer_output_list\u001b[38;5;241m.\u001b[39mappend(layer_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_mas_high:\n",
    "    \n",
    "    for wr in high_mas:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"high_mas_same_nw/{wr/1000.:.0f}_kHz/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating highest MAS rate {wr/1000.:.0f} kHz\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        wr0 = data_pars[\"mas_pars\"][\"mas_w_range\"]\n",
    "        wr1 = [wr0[0], wr]\n",
    "        \n",
    "        data_pars2[\"mas_pars\"][\"mas_w_range\"] = wr1\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        high_mas,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Highest MAS rate\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_mas_high_same_nw.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe2866-ac44-4c65-9bf8-d403245e20bf",
   "metadata": {},
   "source": [
    "# Vary lowest MAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d32bf-5244-43ff-b791-39bdde7903fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_mas_low:\n",
    "    \n",
    "    for wr in low_mas:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"low_mas/{wr/1000.:.0f}_kHz/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating lowest MAS rate {wr/1000.:.0f} kHz\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        wr0 = data_pars[\"mas_pars\"][\"mas_w_range\"]\n",
    "        wr1 = [wr, wr0[1]]\n",
    "        nw0 = data_pars[\"mas_pars\"][\"nw\"]\n",
    "        nw1 = int(nw0 * (wr1[1]-wr1[0]) / (wr0[1]-wr0[0]))\n",
    "        nw1 = max(model_pars[\"batch_input\"]+1, nw1)\n",
    "        \n",
    "        data_pars2[\"mas_pars\"][\"mas_w_range\"] = wr1\n",
    "        data_pars2[\"mas_pars\"][\"nw\"] = nw1\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        low_mas,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Lowest MAS rate\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_mas_low.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02761d-d0a6-42fd-8d06-11545df1738a",
   "metadata": {},
   "source": [
    "# Vary lowest MAS, same number of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d777d4f-398f-41f5-9801-277708395f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_mas_low:\n",
    "    \n",
    "    for wr in low_mas:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"low_mas_same_nw/{wr/1000.:.0f}_kHz/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating lowest MAS rate {wr/1000.:.0f} kHz\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        wr0 = data_pars[\"mas_pars\"][\"mas_w_range\"]\n",
    "        wr1 = [wr, wr0[1]]\n",
    "        \n",
    "        data_pars2[\"mas_pars\"][\"mas_w_range\"] = wr1\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        low_mas,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Lowest MAS rate\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_mas_low_same_nw.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b8d8d-f34b-4e31-96d3-5a20c0996682",
   "metadata": {},
   "source": [
    "# Vary number of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ac704-bfbc-48b6-b859-e5dc4dca88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_nw:\n",
    "    \n",
    "    for nw in np.arange(model_pars[\"batch_input\"], nw_max+1):\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"n_mas/{nw}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating {nw} MAS spectra\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        data_pars2[\"mas_pars\"][\"nw\"] = nw\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        np.arange(model_pars[\"batch_input\"], nw_max+1),\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Number of MAS spectra\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_n_mas.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e6f46-b1f0-4bbc-9adf-ae8d1ea17c80",
   "metadata": {},
   "source": [
    "# Vary noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a273b5-10c8-41fc-bcbf-ba808cc4fbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_noise:\n",
    "    \n",
    "    for noise in noise_levels:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"noise/{noise}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating noise level {noise}\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        data_pars2[\"noise\"] = noise\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        noise_levels,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlog=True,\n",
    "        xlabel=\"Noise level\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_noise.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974fed7b-ed5f-4064-a12f-9a0b1960d11a",
   "metadata": {},
   "source": [
    "# Vary shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335e33f-87d4-44b3-8ecf-8b5c7de050cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_shift:\n",
    "    \n",
    "    for shift, l in zip(shift_values, shift_labels):\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"shift/{l.replace(' ', '_')}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating {l}\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        if not shift:\n",
    "            data_pars2[\"mas_pars\"][\"mas1_s_range\"] = [[0., 0.]]\n",
    "            data_pars2[\"mas_pars\"][\"mas1_s_probs\"] = [1.]\n",
    "            data_pars2[\"mas_pars\"][\"mas2_s_range\"] = [[0., 0.]]\n",
    "            data_pars2[\"mas_pars\"][\"mas2_s_probs\"] = [1.]\n",
    "            data_pars2[\"mas_s_noise\"] = 0.\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        np.arange(len(shift_values)),\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Shift\",\n",
    "        xticks=np.arange(len(shift_values)),\n",
    "        xticklabels=shift_labels,\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_shift.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af29d1e-ca84-4767-b9f0-93cb41e1316c",
   "metadata": {},
   "source": [
    "# Generate MAS independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48506bb7-42f1-4dd6-9ab7-7c78b6e27f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_constant:\n",
    "    \n",
    "    d = fdir + f\"constant/Non_constant/\"\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        \n",
    "    print(\"Generating non-constant dataset\")\n",
    "    \n",
    "    data_pars2 = copy.deepcopy(data_pars)\n",
    "    dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    y_std = []\n",
    "    ys_pred = []\n",
    "    for ibatch in range(n_batch):\n",
    "        # Generate dataset\n",
    "        Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "\n",
    "        print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "        if net.return_all_layers:\n",
    "            if net.ndim == 1:\n",
    "                yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "            elif net.ndim == 2:\n",
    "                yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "        y_std.append(yi_std)\n",
    "        ys_pred.append(yis_pred)\n",
    "\n",
    "    X = torch.cat(X)\n",
    "    y = torch.cat(y)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "    y_std = torch.cat(y_std)\n",
    "    ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "    for ishow in range(n_show):\n",
    "        utils.plot_2d_iso_prediction(\n",
    "            X[ishow].numpy(),\n",
    "            y_pred[ishow].detach().numpy(),\n",
    "            y_trg = y[ishow, 0].numpy(),\n",
    "            xvals=dataset.xgen.f,\n",
    "            yvals=dataset.ygen.f,\n",
    "            wr_factor=dataset.xgen.norm_wr,\n",
    "            show=False,\n",
    "            save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "        )\n",
    "    \n",
    "    # Compute loss\n",
    "    if net.is_ensemble:\n",
    "        ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "        _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "        _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "\n",
    "    else:\n",
    "        _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "        _, [iso_mse, _] = loss2(y_pred, y)\n",
    "\n",
    "    iso_maes.append(iso_mae)\n",
    "    int_maes.append(int_mae)\n",
    "    iso_mses.append(iso_mse)\n",
    "    cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "\n",
    "    d = fdir + f\"constant/Constant/\"\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "    \n",
    "    print(\"Generating constant dataset\")\n",
    "    \n",
    "    y = X[:, -1, :1] / 5.\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:, i, 0] = X[:, -1, 0]\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        y_pred, y_std, ys_pred = net(X)\n",
    "\n",
    "    if net.return_all_layers:\n",
    "        if net.ndim == 1:\n",
    "            y = y.repeat((1, y_pred.shape[1], 1))\n",
    "        elif net.ndim == 2:\n",
    "            y = y.repeat((1, y_pred.shape[1], 1, 1))\n",
    "\n",
    "    for ishow in range(n_show):\n",
    "        utils.plot_2d_iso_prediction(\n",
    "            X[ishow].numpy(),\n",
    "            y_pred[ishow].detach().numpy(),\n",
    "            y_trg = y[ishow, 0].numpy(),\n",
    "            xvals=dataset.xgen.f,\n",
    "            yvals=dataset.ygen.f,\n",
    "            wr_factor=dataset.xgen.norm_wr,\n",
    "            show=False,\n",
    "            save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "        )\n",
    "\n",
    "    # Compute loss\n",
    "    if net.is_ensemble:\n",
    "        ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "        _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "        _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "\n",
    "    else:\n",
    "        _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "        _, [iso_mse, _] = loss2(y_pred, y)\n",
    "\n",
    "    iso_maes.append(iso_mae)\n",
    "    int_maes.append(int_mae)\n",
    "    iso_mses.append(iso_mse)\n",
    "    cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "\n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        np.arange(2),\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlabel=\"Constant\",\n",
    "        xticks=np.arange(2),\n",
    "        xticklabels=[\"Non-constant\", \"Constant\"],\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_constant.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b1a28-5435-4d07-bc22-0524b43485fb",
   "metadata": {},
   "source": [
    "# Vary shift noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a0968-e09e-4499-9552-c815b5a98001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_shift_noise:\n",
    "    \n",
    "    for noise in shift_noise_levels:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"shift_noise/{noise}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating shift noise level {noise}\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        data_pars2[\"mas_s_noise\"] = noise\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        shift_noise_levels,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlog=False,\n",
    "        xlabel=\"Shift noise level\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_shift_noise.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202d241-c482-4343-90d3-524ccf9a99b8",
   "metadata": {},
   "source": [
    "# Vary linewidth noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02028ea7-020c-4e30-8f01-f61299636e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iso_maes = []\n",
    "int_maes = []\n",
    "iso_mses = []\n",
    "cos_sims = []\n",
    "\n",
    "if eval_lw_noise:\n",
    "    \n",
    "    for noise in lw_noise_levels:\n",
    "        \n",
    "        np.random.seed(1)\n",
    "        \n",
    "        d = fdir + f\"lw_noise/{noise}/\"\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        print(f\"Generating linewidth noise level {noise}\")\n",
    "        \n",
    "        # Update data parameters\n",
    "        data_pars2 = copy.deepcopy(data_pars)\n",
    "        data_pars2[\"mas_l_noise\"] = noise\n",
    "        dataset = data.Dataset2D(params_x=data_pars2, params_y=data_pars2)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        ys_pred = []\n",
    "        for ibatch in range(n_batch):\n",
    "            # Generate dataset\n",
    "            Xi, yi = dataset.generate_batch(size=batch_size)\n",
    "            \n",
    "            print(f\"  Batch {ibatch + 1}/{n_batch}\")\n",
    "\n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                yi_pred, yi_std, yis_pred = net(Xi)\n",
    "\n",
    "            if net.return_all_layers:\n",
    "                if net.ndim == 1:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1))\n",
    "                elif net.ndim == 2:\n",
    "                    yi = yi.repeat((1, yi_pred.shape[1], 1, 1))\n",
    "            \n",
    "            X.append(Xi)\n",
    "            y.append(yi)\n",
    "            y_pred.append(yi_pred)\n",
    "            y_std.append(yi_std)\n",
    "            ys_pred.append(yis_pred)\n",
    "        \n",
    "        X = torch.cat(X)\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        y_std = torch.cat(y_std)\n",
    "        ys_pred = torch.cat(ys_pred, dim=1)\n",
    "\n",
    "        for ishow in range(n_show):\n",
    "            utils.plot_2d_iso_prediction(\n",
    "                X[ishow].numpy(),\n",
    "                y_pred[ishow].detach().numpy(),\n",
    "                y_trg = y[ishow, 0].numpy(),\n",
    "                xvals=dataset.xgen.f,\n",
    "                yvals=dataset.ygen.f,\n",
    "                wr_factor=dataset.xgen.norm_wr,\n",
    "                show=False,\n",
    "                save=f\"{d}sample_{ishow+1}.pdf\"\n",
    "            )\n",
    "            \n",
    "        # Compute loss\n",
    "        if net.is_ensemble:\n",
    "            ys = torch.cat([torch.unsqueeze(y.clone(), 0) for _ in range(ys_pred.shape[0])])\n",
    "            _, [iso_mae, int_mae] = loss1(ys_pred, ys)\n",
    "            _, [iso_mse, _] = loss2(ys_pred, ys)\n",
    "            \n",
    "        else:\n",
    "            _, [iso_mae, int_mae] = loss1(y_pred, y)\n",
    "            _, [iso_mse, _] = loss2(y_pred, y)\n",
    "        \n",
    "        iso_maes.append(iso_mae)\n",
    "        int_maes.append(int_mae)\n",
    "        iso_mses.append(iso_mse)\n",
    "        cos_sims.append(compute_cos_sim(y_pred, y))\n",
    "        \n",
    "    iso_maes = np.array(iso_maes)\n",
    "    int_maes = np.array(int_maes)\n",
    "    iso_mses = np.array(iso_mses)\n",
    "    cos_sims = np.array(cos_sims)\n",
    "    \n",
    "    plot_results(\n",
    "        lw_noise_levels,\n",
    "        iso_maes,\n",
    "        int_maes,\n",
    "        iso_mses,\n",
    "        cos_sims,\n",
    "        xlog=True,\n",
    "        xlabel=\"Linewidth noise level\",\n",
    "        show=False,\n",
    "        save=f\"{fdir}eval_lw_noise.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe9be8-d3f9-4a71-9b4a-383c4c0e2e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIPNet",
   "language": "python",
   "name": "pipnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
