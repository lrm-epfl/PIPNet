{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48c4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads=4\n",
    "from torch import nn\n",
    "import scipy as sp\n",
    "\n",
    "import importlib\n",
    "import pickle as pk\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anm\n",
    "\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import data\n",
    "import model\n",
    "import train\n",
    "\n",
    "import nmrglue as ng\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909326be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = \"Ensemble_PIPNet_2022_02_01_5_layers\"\n",
    "\n",
    "in_dir = f\"../data/{mod}/\"\n",
    "fig_dir = f\"../figures/{mod}/\"\n",
    "\n",
    "sel_wrs = [30000., 32000., 34000., 36000., 38000.,\n",
    "           40000., 42000., 44000., 46000., 48000.,\n",
    "           50000., 52000., 54000., 56000., 58000.,\n",
    "           60000., 62000., 64000., 66000., 68000.,\n",
    "           70000., 72000., 74000., 76000., 78000., 80000.]\n",
    "\n",
    "peaks = {\"ampicillin\": [[0.25, 0.7], [1.3, 1.7], [3.5, 4.1], [4.3, 4.7], [4.8, 5.2], [6.1, 6.6], [9.5, 10.5]],\n",
    "         \"aspala\": [[0.5, 1.], [1.9, 2.2], [2.3, 3.], [3.7, 4.1], [4.5, 5.], [7., 7.5], [7.7, 8.2], [12.3, 12.8]],\n",
    "         \"flutamide\": [[0.7, 1.5], [1.8, 2.2]],\n",
    "         \"histidine\": [[2.3, 2.9], [2.8, 3.5], [4.8, 5.2], [7.2, 7.8], [8.6, 9.2], [12, 12.8], [16.7, 17.4]],\n",
    "         \"thymol\": [[0.2, 0.7], [0.8, 1.3], [1.3, 1.8], [3, 3.5], [5, 5.7], [5.7, 6.4], [6.7, 7.2], [9, 9.5]],\n",
    "         \"tyrosine\": [[2.3, 2.7], [6.4, 6.8], [9.7, 10.2]],\n",
    "         \"mdma\": []}\n",
    "\n",
    "evals = {\"sel\": True, \"opt\": True, \"all\": True, \"high\": True, \"low\": True, \"rand\": 0}\n",
    "exp_dir = f\"../data/experimental_spectra/topspin/4096/\"\n",
    "x_scales = [0.2]\n",
    "exp_compounds = [\"ampicillin\", \"aspala\", \"flutamide\", \"histidine\", \"thymol\", \"tyrosine\", \"mdma\"]\n",
    "exp_range = {\"ampicillin\": [1500, 2500],\n",
    "             \"aspala\": [1500, 2500],\n",
    "             \"flutamide\": [1500, 2500],\n",
    "             \"histidine\": [1500, 2500],\n",
    "             \"thymol\": [1500, 2500],\n",
    "             \"tyrosine\": [1500, 2500],\n",
    "             \"mdma\": [1600, 2400],\n",
    "            }\n",
    "\n",
    "int_regions = {\"ampicillin\": [[12., 8.5], [8.5, 3.], [3., -2.]],\n",
    "               \"aspala\": [[15., 10.], [10., 6.], [6., 3.4], [3.4, 1.5], [1.5, 0.]],\n",
    "               \"flutamide\": [[11., 9.], [9., 5.], [5., -2.]],\n",
    "               \"histidine\": [[20., 15.], [15., 10.5], [10.5, 6.5], [6.5, 4.2], [4.2, -2.]],\n",
    "               \"thymol\": [[12., 8.], [8., 4.5], [4.5, 2.7], [2.7, -2]],\n",
    "               \"tyrosine\": [[14., 11.], [11., 9.], [9., 6.1], [6.1, 3.5], [3.5, 0.]],\n",
    "               \"mdma\": [[15., 10.], [10., 7.], [7., 1.]],\n",
    "              }\n",
    "\n",
    "align_regions = {\"ampicillin\": [12., 9.],\n",
    "                 \"aspala\": [15., 11.],\n",
    "                 \"flutamide\": [11., 9.],\n",
    "                 \"histidine\": [18., 16.],\n",
    "                 \"thymol\": [6.7, 5.7],\n",
    "                 \"tyrosine\": [14., 11.],\n",
    "                 \"mdma\": [4., 2.],\n",
    "                }\n",
    "\n",
    "iso_dir = \"../data/experimental_spectra/iso/\"\n",
    "exp_res = {\"ampicillin\": [\"4k\", \"4k\", \"4k\", \"4k\"],\n",
    "           \"aspala\": [\"4k\", \"4k\", \"4k\", \"4k\", \"4k\"],\n",
    "           \"flutamide\": [\"2k\", \"2k\", \"2k\", \"2k\"],\n",
    "           \"histidine\": [\"4k\", \"4k\", \"4k\", \"4k\", \"4k\"],\n",
    "           \"thymol\": [\"4k\", \"4k\", \"4k\", \"4k\"],\n",
    "           \"tyrosine\": [\"4k\", \"4k\", \"4k\", \"4k\", \"4k\"],\n",
    "           \"mdma\": []}\n",
    "exp_parts = {'ampicillin': ['NH3', 'NHAr5', 'Ar6104b', 'Me2'],\n",
    "             'aspala': ['OH', 'NHNH3', 'CHCH', 'CH2', 'CH3'],\n",
    "             'flutamide': ['H5b', 'H38', 'H6', 'H101112'],\n",
    "             'histidine': ['H5', 'H7', 'H618', 'H9', 'H342'],\n",
    "             'thymol': ['H7', 'H321c', 'H4', 'H556'],\n",
    "             'tyrosine': ['COOH', 'OH', 'NH3H76', 'H5823', 'H3dia'],\n",
    "             \"mdma\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2050d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(in_dir):\n",
    "    raise ValueError(f\"Unknown model: {mod}\")\n",
    "    \n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f2c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split(l, delimiter):\n",
    "    \"\"\"\n",
    "    Split a line with the desired delimiter, ignoring delimiters present in arrays or strings\n",
    "    \n",
    "    Inputs: - l     Input line\n",
    "    \n",
    "    Output: - ls    List of sub-strings making up the line\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize sub-strings\n",
    "    ls = []\n",
    "    clean_l = \"\"\n",
    "    \n",
    "    # Loop over all line characters\n",
    "    in_dq = False\n",
    "    in_sq = False\n",
    "    arr_depth = 0\n",
    "    for li in l:\n",
    "        # Identify strings with double quotes\n",
    "        if li == \"\\\"\":\n",
    "            if not in_dq:\n",
    "                in_dq = True\n",
    "            else:\n",
    "                in_dq = False\n",
    "        \n",
    "        # Identify strings with single quotes\n",
    "        if li == \"\\'\":\n",
    "            if not in_sq:\n",
    "                in_sq = True\n",
    "            else:\n",
    "                in_sq = False\n",
    "        \n",
    "        # Identify arrays\n",
    "        if li == \"[\":\n",
    "            if not in_sq and not in_dq:\n",
    "                arr_depth += 1\n",
    "        if li == \"]\":\n",
    "            if not in_sq and not in_dq:\n",
    "                arr_depth -= 1\n",
    "        \n",
    "        # If the delimiter is not within quotes or in an array, split the line at that character\n",
    "        if li == delimiter and not in_dq and not in_sq and arr_depth == 0:\n",
    "            ls.append(clean_l)\n",
    "            clean_l = \"\"\n",
    "        else:\n",
    "            clean_l += li\n",
    "    \n",
    "    ls.append(clean_l)\n",
    "        \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b681b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(l):\n",
    "    \"\"\"\n",
    "    Get the values in an array contained in a line\n",
    "    \n",
    "    Input:  - l         Input line\n",
    "    \n",
    "    Output: - vals      Array of values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify empty array\n",
    "    if l.strip() == \"[]\":\n",
    "        return []\n",
    "    \n",
    "    # Initialize array\n",
    "    vals = []\n",
    "    clean_l = \"\"\n",
    "    \n",
    "    # Loop over all line characters\n",
    "    arr_depth = 0\n",
    "    for li in l:\n",
    "    \n",
    "        # Identify end of array\n",
    "        if li == \"]\":\n",
    "            arr_depth -= 1\n",
    "            \n",
    "            # Check that there are not too many closing brackets for the opening ones\n",
    "            if arr_depth < 0:\n",
    "                raise ValueError(\"Missing \\\"[\\\" for matching the number of \\\"]\\\"\")\n",
    "        \n",
    "        # If we are within the array, extract the character\n",
    "        if arr_depth > 0:\n",
    "            clean_l += li\n",
    "    \n",
    "        # Identify start of array\n",
    "        if li == \"[\":\n",
    "            arr_depth += 1\n",
    "    \n",
    "    # Check that the array is properly closed at the end\n",
    "    if arr_depth > 0:\n",
    "        raise ValueError(\"Missing \\\"]\\\" for matching the number of \\\"[\\\"\")\n",
    "    \n",
    "    # Extract elements in the array\n",
    "    ls = clean_split(clean_l, \",\")\n",
    "    \n",
    "    # Get the value of each element in the array\n",
    "    for li in ls:\n",
    "        vals.append(get_val(li.strip()))\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62025ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(val):\n",
    "    \n",
    "    #Â Remove tailing comma\n",
    "    if val.endswith(\",\"):\n",
    "        val = val[:-1]\n",
    "    \n",
    "    # Float / Int\n",
    "    if val.isnumeric():\n",
    "        \n",
    "        if \".\" in val:\n",
    "            return float(val)\n",
    "        else:\n",
    "            return int(val)\n",
    "    \n",
    "    # Bool\n",
    "    if val.lower() == \"true\":\n",
    "        return True\n",
    "    if val.lower() == \"false\":\n",
    "        return False\n",
    "    \n",
    "    # String\n",
    "    if val.startswith(\"\\\"\"):\n",
    "        return val.split(\"\\\"\")[1]\n",
    "    \n",
    "    # List\n",
    "    if val.startswith(\"[\"):\n",
    "        \n",
    "        return get_array(val)\n",
    "    \n",
    "    # Try to return a float anyway\n",
    "    return float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153731a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model architecture\n",
    "with open(mod + \".py\", \"r\") as F:\n",
    "    lines = F.read().split(\"\\n\")\n",
    "\n",
    "model_pars = {}\n",
    "in_pars = False\n",
    "\n",
    "# Parse script\n",
    "for l in lines:\n",
    "    \n",
    "    # Identify model parameter block start\n",
    "    if \"model_pars = \" in l:\n",
    "        in_pars = True\n",
    "    \n",
    "    # Identify model parameter block end\n",
    "    if l.strip() == \")\":\n",
    "        in_pars = False\n",
    "    \n",
    "    if in_pars:\n",
    "        # Get line\n",
    "        if \"(\" in l:\n",
    "            L = l.split(\"(\")[1].split(\"#\")[0]\n",
    "        else:\n",
    "            L = l.strip().split(\"#\")[0]\n",
    "        \n",
    "        key, val = L.split(\"=\")\n",
    "        \n",
    "        v = get_val(val.strip())\n",
    "        \n",
    "        model_pars[key.strip()] = v\n",
    "\n",
    "model_pars[\"noise\"] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db93cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data parameters\n",
    "with open(mod + \".py\", \"r\") as F:\n",
    "    lines = F.read().split(\"\\n\")\n",
    "\n",
    "data_pars = {}\n",
    "in_pars = False\n",
    "\n",
    "# Parse script\n",
    "for l in lines:\n",
    "    \n",
    "    # Identify model parameter block start\n",
    "    if \"data_pars = \" in l:\n",
    "        in_pars = True\n",
    "    \n",
    "    # Identify model parameter block end\n",
    "    if l.strip() == \")\":\n",
    "        in_pars = False\n",
    "    \n",
    "    if in_pars:\n",
    "        # Get line\n",
    "        if \"(\" in l:\n",
    "            L = l.split(\"(\")[1].split(\"#\")[0]\n",
    "        else:\n",
    "            L = l.strip().split(\"#\")[0]\n",
    "        \n",
    "        if \"=\" in L:\n",
    "        \n",
    "            key, val = L.split(\"=\")\n",
    "        \n",
    "            v = get_val(val.strip())\n",
    "        \n",
    "            data_pars[key.strip()] = v\n",
    "\n",
    "dataset = data.PIPDataset(**data_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef84bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss parameters\n",
    "with open(mod + \".py\", \"r\") as F:\n",
    "    lines = F.read().split(\"\\n\")\n",
    "\n",
    "loss_pars = {}\n",
    "in_pars = False\n",
    "\n",
    "# Parse script\n",
    "for l in lines:\n",
    "    \n",
    "    # Identify model parameter block start\n",
    "    if \"loss_pars = \" in l:\n",
    "        in_pars = True\n",
    "    \n",
    "    # Identify model parameter block end\n",
    "    if l.strip() == \")\":\n",
    "        in_pars = False\n",
    "    \n",
    "    if in_pars:\n",
    "        # Get line\n",
    "        if \"(\" in l:\n",
    "            L = l.split(\"(\")[1].split(\"#\")[0]\n",
    "        else:\n",
    "            L = l.strip().split(\"#\")[0]\n",
    "        \n",
    "        if \"=\" in L:\n",
    "        \n",
    "            key, val = L.split(\"=\")\n",
    "        \n",
    "            v = get_val(val.strip())\n",
    "        \n",
    "            loss_pars[key.strip()] = v\n",
    "            \n",
    "loss_components = []\n",
    "loss_components_with_tot = [\"Total\"]\n",
    "\n",
    "if \"srp_w\" in loss_pars and loss_pars[\"srp_w\"] > 0.:\n",
    "    loss_components.append(\"Sharp component\")\n",
    "    loss_components_with_tot.append(\"Sharp component\")\n",
    "if \"brd_w\" in loss_pars and loss_pars[\"brd_w\"] > 0.:\n",
    "    loss_components.append(\"Broad component\")\n",
    "    loss_components_with_tot.append(\"Broad component\")\n",
    "if \"int_w\" in loss_pars and loss_pars[\"int_w\"] > 0.:\n",
    "    loss_components.append(\"Integral component\")\n",
    "    loss_components_with_tot.append(\"Integral component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e75556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "# Load loss and learning rate\n",
    "all_lrs = np.load(in_dir + \"all_lrs.npy\")\n",
    "all_losses = np.load(in_dir + \"all_losses.npy\")\n",
    "all_val_losses = np.load(in_dir + \"all_val_losses.npy\")\n",
    "\n",
    "try:\n",
    "    all_loss_components = np.load(in_dir + \"all_loss_components.npy\")\n",
    "    all_val_loss_components = np.load(in_dir + \"all_val_loss_components.npy\")\n",
    "    mean_loss_components = np.mean(all_loss_components, axis=1)\n",
    "    mean_val_loss_components = np.mean(all_val_loss_components, axis=1)\n",
    "except:\n",
    "    all_loss_components = None\n",
    "    all_val_loss_components = None\n",
    "    mean_loss_components = None\n",
    "    mean_val_loss_components = None\n",
    "\n",
    "mean_losses = np.mean(all_losses, axis=1)\n",
    "mean_val_losses = np.mean(all_val_losses, axis=1)\n",
    "\n",
    "n_chk = all_losses.shape[0]\n",
    "best_chk = np.argmin(mean_val_losses)\n",
    "print(best_chk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86714c88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e178192",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.ConvLSTMEnsemble(**model_pars)\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caf186",
   "metadata": {},
   "source": [
    "# Evaluate experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b48ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topspin_spectrum(d):\n",
    "    \n",
    "    pd = f\"{d}pdata/1/\"\n",
    "    \n",
    "    fr = pd + \"1r\"\n",
    "    fi = pd + \"1i\"\n",
    "\n",
    "    with open(fr, \"rb\") as F:\n",
    "        dr = np.fromfile(F, np.int32).astype(float)\n",
    "\n",
    "    with open(fi, \"rb\") as F:\n",
    "        di = np.fromfile(F, np.int32).astype(float)\n",
    "\n",
    "    with open(f\"{d}acqus\", \"r\") as F:\n",
    "        lines = F.read().split(\"\\n\")\n",
    "\n",
    "    for l in lines:\n",
    "        if l.startswith(\"##$MASR\"):\n",
    "            wr = int(l.split(\"=\")[1].strip())\n",
    "        if l.startswith(\"##$TD=\"):\n",
    "            TD = int(l.split(\"=\")[1].strip())\n",
    "        if l.startswith(\"##$SW_h=\"):\n",
    "            SW = float(l.split(\"=\")[1].strip())\n",
    "\n",
    "    with open(f\"{pd}procs\", \"r\") as F:\n",
    "        lines = F.read().split(\"\\n\")\n",
    "\n",
    "    for l in lines:\n",
    "        if l.startswith(\"##$SI=\"):\n",
    "            n_pts = int(l.split(\"=\")[1].strip())\n",
    "\n",
    "        if l.startswith(\"##$OFFSET=\"):\n",
    "            offset = float(l.split(\"=\")[1].strip())\n",
    "\n",
    "        if l.startswith(\"##$SF=\"):\n",
    "            SF = float(l.split(\"=\")[1].strip())\n",
    "            \n",
    "    AQ = TD / (2 * SW)\n",
    "\n",
    "    hz = offset * SF - np.arange(n_pts) / (2 * AQ * n_pts / TD)\n",
    "    \n",
    "    ppm = hz / SF\n",
    "\n",
    "    return dr, di, wr, ppm, hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7cbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_topspin(in_dir, compound):\n",
    "    \n",
    "    d0 = f\"{in_dir}{compound}/\"\n",
    "    \n",
    "    ws = []\n",
    "    X = []\n",
    "    \n",
    "    for d in os.listdir(d0):\n",
    "        if d.isnumeric():\n",
    "            Xi, _, wr, ppm, hz = load_topspin_spectrum(f\"{d0}{d}/\")\n",
    "            X.append(Xi)\n",
    "            ws.append(wr)\n",
    "    \n",
    "    sorted_inds = np.argsort(ws)\n",
    "    \n",
    "    sorted_ws = np.array([ws[i] for i in sorted_inds])\n",
    "    \n",
    "    sorted_X = np.array([X[i] for i in sorted_inds])\n",
    "    \n",
    "    return ppm, sorted_ws, sorted_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531b218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fit_model(in_dir, compound, parts, res):\n",
    "    \n",
    "    ys_part_means = []\n",
    "    ys_part_stds = []\n",
    "    ys_ppms = []\n",
    "    \n",
    "    if len(parts) == 0 or len(res) == 0:\n",
    "        return [], [], []\n",
    "    \n",
    "    for p, n in zip(parts, res):\n",
    "        \n",
    "        \n",
    "        d = f\"{in_dir}{compound}_{n}/\"\n",
    "        \n",
    "        if not os.path.exists(d):\n",
    "            return [], [], []\n",
    "    \n",
    "        ys_part = []\n",
    "\n",
    "        i_guess = 1\n",
    "        while os.path.exists(f\"{d}{compound[:3]}_{p}_guess_r{i_guess}.mat\"):\n",
    "\n",
    "            m = scipy.io.loadmat(f\"{d}{compound[:3]}_{p}_guess_r{i_guess}.mat\")\n",
    "\n",
    "            ys_part.append(m[\"x\"][:-3])\n",
    "            ppm = m[\"ppm\"][0, m[\"range\"][0]]\n",
    "            \n",
    "            i_guess += 1\n",
    "        \n",
    "        if len(ys_ppms) > 0:\n",
    "            already_ppms = np.concatenate(ys_ppms, axis=0)\n",
    "            inds = np.where(np.logical_or(ppm < np.min(already_ppms), ppm > np.max(already_ppms)))[0]\n",
    "        else:\n",
    "            inds = range(len(ppm))\n",
    "        \n",
    "        ys_ppms.append(ppm[inds])\n",
    "        ys_part = np.concatenate(ys_part, axis=1)\n",
    "        ys_part_means.append(np.mean(ys_part, axis=1)[inds])\n",
    "        ys_part_stds.append(np.std(ys_part, axis=1)[inds])\n",
    "    \n",
    "    ys_ppms = np.concatenate(ys_ppms, axis=0)\n",
    "    ys_part_means = np.concatenate(ys_part_means, axis=0)\n",
    "    ys_part_stds = np.concatenate(ys_part_stds, axis=0)\n",
    "    \n",
    "    return ys_ppms, ys_part_means, ys_part_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5573688b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(X, ws, data_pars, x_max=0.25):\n",
    "    \n",
    "    inds = np.argsort(ws)\n",
    "    X_torch = torch.Tensor(X[inds])\n",
    "    X_torch = torch.unsqueeze(X_torch, dim=0)\n",
    "    X_torch = torch.unsqueeze(X_torch, dim=2)\n",
    "    \n",
    "    X_torch /= torch.max(X_torch)\n",
    "    X_torch *= x_max\n",
    "    \n",
    "    if data_pars[\"encode_w\"]:\n",
    "        W = torch.Tensor(ws[inds])\n",
    "        W = torch.unsqueeze(W, dim=0)\n",
    "        W = torch.unsqueeze(W, dim=2)\n",
    "        W = torch.unsqueeze(W, dim=3)\n",
    "        W = W.repeat(1, 1, 1, X_torch.shape[-1])\n",
    "        \n",
    "        if data_pars[\"norm_wr\"]:\n",
    "            W -= data_pars[\"mas_w_range\"][0]\n",
    "            W /= data_pars[\"mas_w_range\"][1] - data_pars[\"mas_w_range\"][0]\n",
    "    \n",
    "    X_torch = torch.cat([X_torch, W], dim=2)\n",
    "    \n",
    "    return X_torch, ws[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a86df6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_exp(ppm, X, show=True, save=None, x_offset=0., xl=[20., -5.], c0=[0., 1., 1.], dc = [0., -1., 0.]):\n",
    "    \n",
    "    # Initialize figure\n",
    "    fig = plt.figure(figsize=(4,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    if n == 1:\n",
    "        colors = [[ci + dci for ci, dci in zip(c0, dc)]]\n",
    "        \n",
    "    else:\n",
    "        colors = [[ci + (dci * i / (n-1)) for ci, dci in zip(c0, dc)] for i in range(n)]\n",
    "    \n",
    "    try:\n",
    "        X2 = np.copy(X.numpy())\n",
    "    except:\n",
    "        X2 = np.copy(X)\n",
    "    \n",
    "    X2 /= np.max(X2)\n",
    "    \n",
    "    # Plot inputs\n",
    "    for i, (c, x) in enumerate(zip(colors, X2)):\n",
    "        ax.plot(ppm, x + i * x_offset, color=c, linewidth=1)\n",
    "    \n",
    "    # Update axis\n",
    "    ax.set_xlim(xl)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Chemical shift [ppm]\")\n",
    "    \n",
    "    # Cleanup layout\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    # Show figure\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    # Close figure\n",
    "    plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "293d8735-f1f7-485f-9776-faa6956a4b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_exp_vs_pred(ppm, X, y_pred, y_std, ppm_trg, y_trg_avg, y_trg_std, show=True, save=None, x_offset=0.,\n",
    "                     y0_pred=0., y0_trg=0., y_pred_scale=0.5, y_trg_scale=0.5, reverse_trg=False, xl=[20., -5.], c0=[0., 1., 1.], dc = [0., -1., 0.]):\n",
    "    \n",
    "    # Initialize figure\n",
    "    fig = plt.figure(figsize=(4,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    if n == 1:\n",
    "        colors = [[ci + dci for ci, dci in zip(c0, dc)]]\n",
    "        \n",
    "    else:\n",
    "        colors = [[ci + (dci * i / (n-1)) for ci, dci in zip(c0, dc)] for i in range(n)]\n",
    "    \n",
    "    try:\n",
    "        X2 = np.copy(X.numpy())\n",
    "    except:\n",
    "        X2 = np.copy(X)\n",
    "    \n",
    "    X2 /= np.max(X2)\n",
    "    \n",
    "    try:\n",
    "        y_pred2 = y_pred.numpy()\n",
    "        y_std2 = y_std.numpy()\n",
    "    except:\n",
    "        y_pred2 = y_pred\n",
    "        y_std2 = y_std\n",
    "    \n",
    "    factor = np.max(y_pred2) / y_pred_scale\n",
    "    y_pred2 /= factor\n",
    "    y_std2 /= factor\n",
    "    \n",
    "    if len(y_trg_avg) > 0:\n",
    "        factor = np.max(y_trg_avg) / y_trg_scale\n",
    "        y_trg_avg2 = y_trg_avg / factor\n",
    "        y_trg_std2 = y_trg_std / factor\n",
    "    \n",
    "    \n",
    "    # Plot inputs\n",
    "    for i, (c, x) in enumerate(zip(colors, X2)):\n",
    "        ax.plot(ppm, x + i * x_offset, color=c, linewidth=1)\n",
    "    \n",
    "    # Plot predictions\n",
    "    ax.plot(ppm, y_pred2 + y0_pred, \"r\", linewidth=1)\n",
    "    ax.fill_between(ppm, y_pred2 - y_std2 + y0_pred, y_pred2 + y_std2 + y0_pred, color=\"r\", alpha=0.3)\n",
    "    \n",
    "    if len(y_trg_avg) > 0:\n",
    "        # Plot target\n",
    "        if reverse_trg:\n",
    "            ax.plot(ppm_trg, -y_trg_avg2 + y0_trg, \"k\", linewidth=1)\n",
    "            ax.fill_between(ppm_trg, -y_trg_avg2 - y_trg_std2 + y0_trg, -y_trg_avg2 + y_trg_std2 + y0_trg, color=\"k\", alpha=0.3)\n",
    "\n",
    "        else:\n",
    "            ax.plot(ppm_trg, y_trg_avg2 + y0_trg, \"k\", linewidth=1)\n",
    "            ax.fill_between(ppm_trg, y_trg_av2g - y_trg_std2 + y0_trg, y_trg_avg2 + y_trg_std2 + y0_trg, color=\"k\", alpha=0.3)\n",
    "\n",
    "    # Update axis\n",
    "    ax.set_xlim(xl)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Chemical shift [ppm]\")\n",
    "    \n",
    "    # Cleanup layout\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    # Show figure\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    # Close figure\n",
    "    plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03162193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linewidth(x, y, r, nfit=3):\n",
    "    \n",
    "    inds = np.where(np.logical_and(x > r[0], x < r[1]))[0]\n",
    "\n",
    "    dx = np.mean(x[1:] - x[:-1])\n",
    "    \n",
    "    top = np.max(y[inds])\n",
    "    \n",
    "    i0 = np.argmax(y[inds])\n",
    "    \n",
    "    xr = None\n",
    "    xl = None\n",
    "    \n",
    "    for i, j in zip(inds[:-1], inds[1:]):\n",
    "        if y[i] > top / 2 and y[j] < top / 2:\n",
    "            \n",
    "            dy = y[j] - y[i]\n",
    "            \n",
    "            dy2 = (top / 2) - y[i]\n",
    "            \n",
    "            xr = x[i] + dx * dy2 / dy\n",
    "            \n",
    "        \n",
    "        if y[i] < top / 2 and y[j] > top / 2:\n",
    "            \n",
    "            dy = y[j] - y[i]\n",
    "            \n",
    "            dy2 = (top / 2) - y[i]\n",
    "            \n",
    "            xl = x[i] + dx * dy2 / dy\n",
    "    \n",
    "    if xl is None:\n",
    "        xl = x[inds[0]]\n",
    "    if xr is None:\n",
    "        xr = x[inds[-1]]\n",
    "    \n",
    "    return abs(xl - xr), x[inds[i0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f02b0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lw(all_lws_fit, all_lws_net, all_pks_fit, all_pks_net, compounds, save):\n",
    "    \n",
    "    fig = plt.figure(figsize=(7,3))\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "    for lws_fit, lws_net in zip(all_lws_fit, all_lws_net):\n",
    "        ax1.scatter(lws_fit, lws_net, s=5)\n",
    "\n",
    "    for pks_fit, pks_net in zip(all_pks_fit, all_pks_net):\n",
    "        ax2.scatter(pks_fit, pks_net, s=5)\n",
    "\n",
    "    ax1.set_xlabel(\"Fitted linewidth [ppm]\")\n",
    "    ax1.set_ylabel(\"PIPNet linewidth [ppm]\")\n",
    "    ax2.set_xlabel(\"Fitted peak [ppm]\")\n",
    "    ax2.set_ylabel(\"PIPNet peak [ppm]\")\n",
    "\n",
    "    ax2.legend(compounds)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"{save}_preds.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(7,3))\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "    for lws_fit, lws_net in zip(all_lws_fit, all_lws_net):\n",
    "        ax1.scatter(lws_fit, lws_net - lws_fit, s=5)\n",
    "\n",
    "    for pks_fit, pks_net in zip(all_pks_fit, all_pks_net):\n",
    "        ax2.scatter(pks_fit, pks_net - pks_fit, s=5)\n",
    "\n",
    "    ax1.set_xlabel(\"Fitted linewidth [ppm]\")\n",
    "    ax1.set_ylabel(\"linewidth difference [ppm]\")\n",
    "    ax2.set_xlabel(\"Fitted peak [ppm]\")\n",
    "    ax2.set_ylabel(\"peak difference [ppm]\")\n",
    "\n",
    "    lw_mae = np.mean(np.abs(np.concatenate(all_lws_fit) - np.concatenate(all_lws_net)))\n",
    "    pk_mae = np.mean(np.abs(np.concatenate(all_pks_fit) - np.concatenate(all_pks_net)))\n",
    "\n",
    "    ax1.title.set_text(f\"MAE = {lw_mae:.2f} ppm\")\n",
    "    ax2.title.set_text(f\"MAE = {pk_mae:.2f} ppm\")\n",
    "\n",
    "    ax2.legend(compounds)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"{save}_preds_diff.pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f08bd47-9622-41ed-8d86-d68a50b46faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_integrals(ppm, X, y, regions):\n",
    "    \n",
    "    X_int = []\n",
    "    y_int = []\n",
    "    \n",
    "    for r1, r2 in regions:\n",
    "        p1 = min(max(1, np.argmin(np.abs(ppm - r1))), len(ppm) - 2)\n",
    "        p2 = min(max(1, np.argmin(np.abs(ppm - r2))), len(ppm) - 2)\n",
    "        \n",
    "        if p1 > p2:\n",
    "            tmp = p1\n",
    "            p1 = p2\n",
    "            p2 = tmp\n",
    "        \n",
    "        X_int.append(np.sum(X[p1:p2]))\n",
    "        y_int.append(np.sum(y[p1:p2]))\n",
    "        \n",
    "    X_int = np.array(X_int) / np.sum(X_int)\n",
    "    y_int = np.array(y_int) / np.sum(y_int)\n",
    "    \n",
    "    return X_int, y_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05b3fe5a-59f5-4226-b65d-79aa1ece29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_integrals(all_X_int, all_y_int, compounds, int_regions, w=0.2, label_h=0.1, show=True, save=None):\n",
    "    \n",
    "    # Compound separations\n",
    "    sep = []\n",
    "    mid = []\n",
    "    labels = []\n",
    "    bounds = []\n",
    "    i = 0\n",
    "    for k in compounds:\n",
    "        if k in int_regions:\n",
    "            l = len(int_regions[k])\n",
    "            labels.append(k)\n",
    "            sep.append(i+l - 0.5)\n",
    "            mid.append(i + (l / 2) - 0.5)\n",
    "            i += l\n",
    "            bounds.append([r[1] for r in int_regions[k][:-1]])\n",
    "    sep = sep[:-1]\n",
    "    \n",
    "    err_avg = []\n",
    "    err_std = []\n",
    "    for xint, yint in zip(all_X_int, all_y_int):\n",
    "        err_avg.append(np.mean(np.abs(xint-yint) / xint*100))\n",
    "        err_std.append(np.std(np.abs(xint-yint) / xint*100))\n",
    "    \n",
    "    x = np.array(range(i))\n",
    "    \n",
    "    xint = np.concatenate(all_X_int)\n",
    "    yint = np.concatenate(all_y_int)\n",
    "    \n",
    "    M = max(np.max(xint), np.max(yint)) * 1.1\n",
    "    \n",
    "    fig = plt.figure(figsize=(i*0.4,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    ax.bar(x-(w/2), xint, width=w)\n",
    "    ax.bar(x+(w/2), yint, width=w)\n",
    "    \n",
    "    ax.legend([\"100 kHz MAS\", \"PIPNet\"], bbox_to_anchor=(0.,0.95), loc=\"upper left\")\n",
    "    \n",
    "    for s in sep:\n",
    "        ax.plot([s, s], [0., M], \"k\")\n",
    "    \n",
    "    lx = 0.5\n",
    "    for b in bounds:\n",
    "        for bi in b:\n",
    "            ax.plot([lx, lx], [0, label_h], \"k:\")\n",
    "            ax.text(lx, label_h, f\" {bi} ppm\", rotation=90, ha=\"center\", va=\"bottom\", size=8)\n",
    "            lx += 1\n",
    "        lx += 1\n",
    "    \n",
    "    for em, es, m in zip(err_avg, err_std, mid):\n",
    "        ax.text(m, M*0.99, f\"{em:.0f}Â±{es:.0f}% error\", ha=\"center\", va=\"top\", size=8)\n",
    "    \n",
    "    ax.set_xticks(mid)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    ax.set_ylabel(\"Relative integral\")\n",
    "    \n",
    "    ax.set_ylim(0., M)\n",
    "    ax.set_xlim(-0.5, i-0.5)\n",
    "    \n",
    "    if save is not None:\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9165aaa-b36b-44d2-a48b-f084f5f51150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum(ppm, X, r, method=\"direct\"):\n",
    "    \n",
    "    r0 = min(r)\n",
    "    r1 = max(r)\n",
    "    \n",
    "    if method == \"direct\":\n",
    "        \n",
    "        inds = np.where(np.logical_and(ppm > r0, ppm < r1))[0]\n",
    "        \n",
    "        i0 = np.argmax(X[inds])\n",
    "        w0 = ppm[inds[i0]]\n",
    "        \n",
    "    elif method == \"interp\":\n",
    "        \n",
    "        inds = np.where(np.logical_and(ppm > r0, ppm < r1))[0]\n",
    "        f = sp.interpolate.interp1d(range(len(inds)), X[inds], kind=\"cubic\")\n",
    "        \n",
    "        x = np.linspace(0, len(inds)-1, 1001)\n",
    "        x_ppm = ppm[inds[0]] + x * (ppm[inds[1]] - ppm[inds[0]])\n",
    "        y = f(x)\n",
    "        w0 = x_ppm[np.argmax(y)]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3542ce-539c-4eef-94dd-340d469f6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_spectrum(hz, Xr, Xi, dw):\n",
    "    \n",
    "    n = Xr.shape[0]\n",
    "    t = np.arange(n) / np.abs(hz[1] - hz[0]) / n\n",
    "    \n",
    "    X = Xr + 1j * Xi\n",
    "    \n",
    "    T = np.fft.ifft(X)\n",
    "    \n",
    "    T *= np.exp(1j*dw*t * 2 * np.pi)\n",
    "    X = np.fft.fft(T)\n",
    "    Xr = np.real(X)\n",
    "    Xi = np.imag(X)\n",
    "    \n",
    "    return Xr, Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17921a87-fa1c-4a48-a6fc-7b458d366c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_shift_exp_topspin(in_dir, compound, align_region, align_ind=-1, method=\"interp\"):\n",
    "    \n",
    "    d0 = f\"{in_dir}{compound}/\"\n",
    "    \n",
    "    ws = []\n",
    "    X_real = []\n",
    "    X_imag = []\n",
    "    for d in os.listdir(d0):\n",
    "        if d.isnumeric():\n",
    "            Xr, Xi, wr, ppm, hz = load_topspin_spectrum(f\"{d0}{d}/\")\n",
    "            X_real.append(Xr)\n",
    "            X_imag.append(Xi)\n",
    "            ws.append(wr)\n",
    "    \n",
    "    sorted_inds = np.argsort(ws)\n",
    "    \n",
    "    sorted_ws = np.array([ws[i] for i in sorted_inds])\n",
    "    \n",
    "    sorted_Xr = np.array([X_real[i] for i in sorted_inds])\n",
    "    sorted_Xi = np.array([X_imag[i] for i in sorted_inds])\n",
    "    \n",
    "    # Extract target shift\n",
    "    align_region_hz = [hz[np.argmin(np.abs(ppm - align_region[0]))], hz[np.argmin(np.abs(ppm - align_region[1]))]]\n",
    "    w0 = get_maximum(hz, sorted_Xr[align_ind], align_region_hz, method=method)\n",
    "    w0_ppm = get_maximum(ppm, sorted_Xr[align_ind], align_region, method=method)\n",
    "    \n",
    "    shifted_Xr = []\n",
    "    shifted_Xi = []\n",
    "    all_dw = []\n",
    "    all_dw_ppm = []\n",
    "    \n",
    "    all_w = []\n",
    "    for Xr, Xi in zip(sorted_Xr, sorted_Xi):\n",
    "        # Get actual shift\n",
    "        this_w = get_maximum(hz, Xr, align_region_hz, method=method)\n",
    "        this_w_ppm = get_maximum(ppm, Xr, align_region, method=method)\n",
    "        dw = this_w - w0\n",
    "        all_dw.append(this_w- w0)\n",
    "        all_dw_ppm.append(this_w_ppm- w0_ppm)\n",
    "        \n",
    "        # Shift spectrum\n",
    "        Xr2, Xi2 = shift_spectrum(hz, Xr, Xi, dw)\n",
    "        \n",
    "        shifted_Xr.append(Xr2)\n",
    "        shifted_Xi.append(Xi2)\n",
    "    \n",
    "    return ppm, sorted_ws, np.array(shifted_Xr), np.array(shifted_Xi), np.array(all_dw), np.array(all_dw_ppm), sorted_Xr, sorted_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e09b78-162e-4795-8ff2-4f7eeb156eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ampicillin\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "aspala\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "flutamide\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "histidine\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "thymol\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "tyrosine\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n",
      "mdma\n",
      "  Predictions on selected MAS rates...\n",
      "  Predictions on optimal MAS rates...\n",
      "  Predictions on all MAS rates...\n",
      "  Predictions on lowest MAS rates...\n",
      "  Predictions on highest MAS rates...\n"
     ]
    }
   ],
   "source": [
    "align_ind = -1\n",
    "\n",
    "# Load best model\n",
    "net.load_state_dict(torch.load(in_dir + f\"checkpoint_{best_chk+1}_network\", map_location=torch.device(\"cpu\")))\n",
    "\n",
    "for xscale in x_scales:\n",
    "\n",
    "    all_lws_fit = []\n",
    "    all_pks_fit = []\n",
    "\n",
    "    sel_all_lws_net = []\n",
    "    sel_all_pks_net = []\n",
    "    opt_all_lws_net = []\n",
    "    opt_all_pks_net = []\n",
    "    all_all_lws_net = []\n",
    "    all_all_pks_net = []\n",
    "    low_all_lws_net = []\n",
    "    low_all_pks_net = []\n",
    "    high_all_lws_net = []\n",
    "    high_all_pks_net = []\n",
    "    rand_all_lws_net = []\n",
    "    rand_all_pks_net = []\n",
    "\n",
    "    fdir = fig_dir + f\"eval_exp_4k_scale_{xscale}_shifted_{align_ind}/\"\n",
    "    if not os.path.exists(fdir):\n",
    "        os.mkdir(fdir)\n",
    "\n",
    "    all_X_int = []\n",
    "    all_y_int = []\n",
    "    sel_X_int = []\n",
    "    sel_y_int = []\n",
    "    opt_X_int = []\n",
    "    opt_y_int = []\n",
    "    all_X_int = []\n",
    "    all_y_int = []\n",
    "    low_X_int = []\n",
    "    low_y_int = []\n",
    "    high_X_int = []\n",
    "    high_y_int = []\n",
    "    rand_X_int = []\n",
    "    rand_y_int = []\n",
    "\n",
    "    for compound in exp_compounds:\n",
    "        r = exp_range[compound]\n",
    "        print(compound)\n",
    "        ys_ppms, ys_part_means, ys_part_stds = extract_fit_model(iso_dir, compound,\n",
    "                                                                 exp_parts[compound], exp_res[compound])\n",
    "        ppm, ws, X, _, all_dw, all_dw_ppm, X0, _ = extract_and_shift_exp_topspin(exp_dir, compound, align_regions[compound], align_ind=align_ind)\n",
    "\n",
    "        if len(ys_part_means) > 0:\n",
    "            ymax = np.max(ys_part_means)\n",
    "            ys_part_means /= ymax / 0.5\n",
    "            ys_part_stds /= ymax / 0.5\n",
    "\n",
    "        ppm = ppm[r[0]:r[1]]\n",
    "        X = X[:, r[0]:r[1]]\n",
    "\n",
    "        X /= np.sum(X, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plot_exp(ppm, X, xl=align_regions[compound], show=False, save=f\"{fdir}{compound}_exp.pdf\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,3))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.plot(ws / 1000, all_dw)\n",
    "        ax.set_xlabel(\"MAS rate [kHz]\")\n",
    "        ax.set_ylabel(\"Peak difference [Hz]\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"{fdir}{compound}_dw_hz.pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,3))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.plot(ws / 1000, all_dw_ppm)\n",
    "        ax.set_xlabel(\"MAS rate [kHz]\")\n",
    "        ax.set_ylabel(\"Peak difference [ppm]\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"{fdir}{compound}_dw_ppm.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "        X_torch, ws = make_input(X, ws, data_pars)\n",
    "\n",
    "        lws_fit = []\n",
    "        pks_fit = []\n",
    "\n",
    "        for p in peaks[compound]:\n",
    "\n",
    "            lw, pk = extract_linewidth(ys_ppms, ys_part_means, p)\n",
    "\n",
    "            lws_fit.append(lw)\n",
    "            pks_fit.append(pk)\n",
    "\n",
    "        all_lws_fit.append(np.array(lws_fit))\n",
    "        all_pks_fit.append(np.array(pks_fit))\n",
    "\n",
    "        # Selected rates\n",
    "        if evals[\"sel\"]:\n",
    "\n",
    "            print(\"  Predictions on selected MAS rates...\")\n",
    "\n",
    "            w_inds = []\n",
    "            for w in sel_wrs:\n",
    "                w_inds.append(np.argmin(np.abs(ws - w)))\n",
    "\n",
    "            X_net = X_torch[:, w_inds]\n",
    "            X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "            y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "            y_pred = y_pred.detach().numpy()[0]\n",
    "            y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_sel_w_pred_{i+1}.pdf\")\n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_sel_w_pred_final.pdf\")\n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            sel_all_lws_net.append(np.array(lws_net))\n",
    "            sel_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            sel_X_int.append(X_int)\n",
    "            sel_y_int.append(y_int)\n",
    "\n",
    "        # Optimized rates\n",
    "        if evals[\"opt\"]:\n",
    "\n",
    "            print(\"  Predictions on optimal MAS rates...\")\n",
    "\n",
    "            opt_wrs = np.linspace(data_pars[\"mas_w_range\"][0], data_pars[\"mas_w_range\"][1], num=data_pars[\"nw\"])\n",
    "\n",
    "            w_inds = []\n",
    "            for w in opt_wrs:\n",
    "                w_inds.append(np.argmin(np.abs(ws - w)))\n",
    "\n",
    "            X_net = X_torch[:, w_inds]\n",
    "            X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "            y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "            y_pred = y_pred.detach().numpy()[0]\n",
    "            y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_opt_w_pred_{i+1}.pdf\")\n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_opt_w_pred_final.pdf\")\n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            opt_all_lws_net.append(np.array(lws_net))\n",
    "            opt_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            opt_X_int.append(X_int)\n",
    "            opt_y_int.append(y_int)\n",
    "\n",
    "        # All rates\n",
    "        if evals[\"all\"]:\n",
    "\n",
    "            print(\"  Predictions on all MAS rates...\")\n",
    "\n",
    "            w_inds = np.argsort(ws)\n",
    "\n",
    "            X_net = X_torch[:, w_inds]\n",
    "            X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "            y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "            y_pred = y_pred.detach().numpy()[0]\n",
    "            y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_all_w_pred_{i+1}.pdf\") \n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_all_w_pred_final.pdf\") \n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            all_all_lws_net.append(np.array(lws_net))\n",
    "            all_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            all_X_int.append(X_int)\n",
    "            all_y_int.append(y_int)\n",
    "\n",
    "        # Lowest rates\n",
    "        if evals[\"low\"]:\n",
    "\n",
    "            print(\"  Predictions on lowest MAS rates...\")\n",
    "\n",
    "            X_net = X_torch[:, :data_pars[\"nw\"]]\n",
    "            X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "            y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "            y_pred = y_pred.detach().numpy()[0]\n",
    "            y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_low_w_pred_{i+1}.pdf\")\n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_low_w_pred_final.pdf\")\n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            low_all_lws_net.append(np.array(lws_net))\n",
    "            low_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            low_X_int.append(X_int)\n",
    "            low_y_int.append(y_int)\n",
    "\n",
    "        # Highest rates\n",
    "        if evals[\"high\"]:\n",
    "\n",
    "            print(\"  Predictions on highest MAS rates...\")\n",
    "\n",
    "            X_net = X_torch[:, -data_pars[\"nw\"]:]\n",
    "            X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "            y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "            y_pred = y_pred.detach().numpy()[0]\n",
    "            y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_high_w_pred_{i+1}.pdf\")\n",
    "\n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_high_w_pred_final.pdf\")\n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            high_all_lws_net.append(np.array(lws_net))\n",
    "            high_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            high_X_int.append(X_int)\n",
    "            high_y_int.append(y_int)\n",
    "\n",
    "        #Â Randomly selected rates\n",
    "        if evals[\"rand\"] > 0:\n",
    "\n",
    "            print(\"  Predictions on randomly selected MAS rates...\")\n",
    "\n",
    "            all_ys = []\n",
    "            for k in range(evals[\"rand\"]):\n",
    "\n",
    "                print(f\"    Selection {k+1}/{evals['rand']}...\")\n",
    "\n",
    "                w_inds = np.sort(np.random.choice(range(X.shape[0]), size=data_pars[\"nw\"], replace=False))\n",
    "\n",
    "                X_net = X_torch[:, w_inds]\n",
    "                X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / xscale\n",
    "\n",
    "                y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "                y_pred = y_pred.detach().numpy()[0]\n",
    "                y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "                ymax = np.max(y_pred)\n",
    "                y_pred /= ymax / 0.5\n",
    "\n",
    "                y_std /= ymax / 0.5\n",
    "\n",
    "                all_ys.append(ys.detach().numpy()[:, 0])\n",
    "\n",
    "                for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                    plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                     y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                     save=f\"{fdir}{compound}_rand_w_{k+1}_pred_{i+1}.pdf\")\n",
    "\n",
    "                plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_rand_w_{k+1}_pred_final.pdf\")\n",
    "\n",
    "            ys = np.concatenate(all_ys, axis=0)\n",
    "            y_pred = np.mean(ys, axis=0)\n",
    "            y_std = np.std(ys, axis=0)\n",
    "\n",
    "            ymax = np.max(y_pred)\n",
    "            y_pred /= ymax / 0.5\n",
    "\n",
    "            y_std /= ymax / 0.5\n",
    "\n",
    "            for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "                plot_exp_vs_pred(ppm, X[-1:], yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                                 y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                                 save=f\"{fdir}{compound}_rands_pred_{i+1}.pdf\")\n",
    "\n",
    "            plot_exp_vs_pred(ppm, X, yi_pred, yi_std, ys_ppms, ys_part_means, ys_part_stds, x_offset=0.1,\n",
    "                             y0_pred=-0.1, y0_trg=-0.1, reverse_trg=True, show=False,\n",
    "                             save=f\"{fdir}{compound}_rands_pred_final.pdf\")\n",
    "\n",
    "            lws_net = []\n",
    "            pks_net = []\n",
    "\n",
    "            for p in peaks[compound]:\n",
    "\n",
    "                lw, pk = extract_linewidth(ppm, yi_pred, p)\n",
    "\n",
    "                lws_net.append(lw)\n",
    "                pks_net.append(pk)\n",
    "\n",
    "            rand_all_lws_net.append(np.array(lws_net))\n",
    "            rand_all_pks_net.append(np.array(pks_net))\n",
    "\n",
    "            X_int, y_int = compare_integrals(ppm, X[-1], y_pred[-1], int_regions[compound])\n",
    "            rand_X_int.append(X_int)\n",
    "            rand_y_int.append(y_int)\n",
    "\n",
    "\n",
    "    if len(sel_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, sel_all_lws_net, all_pks_fit, sel_all_pks_net, exp_compounds, f\"{fdir}sel\")\n",
    "\n",
    "    if len(opt_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, opt_all_lws_net, all_pks_fit, opt_all_pks_net, exp_compounds, f\"{fdir}opt\")\n",
    "\n",
    "    if len(all_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, all_all_lws_net, all_pks_fit, all_all_pks_net, exp_compounds, f\"{fdir}all\")\n",
    "\n",
    "    if len(low_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, low_all_lws_net, all_pks_fit, low_all_pks_net, exp_compounds, f\"{fdir}low\")\n",
    "\n",
    "    if len(high_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, high_all_lws_net, all_pks_fit, high_all_pks_net, exp_compounds, f\"{fdir}high\")\n",
    "\n",
    "    if len(rand_all_lws_net) > 0:\n",
    "        plot_lw(all_lws_fit, rand_all_lws_net, all_pks_fit, rand_all_pks_net, exp_compounds, f\"{fdir}rand\")\n",
    "\n",
    "    if len(sel_y_int) > 0:\n",
    "        plot_integrals(sel_X_int, sel_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}sel_integrals.pdf\")\n",
    "\n",
    "    if len(opt_y_int) > 0:\n",
    "        plot_integrals(opt_X_int, opt_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}opt_integrals.pdf\")\n",
    "\n",
    "    if len(all_y_int) > 0:\n",
    "        plot_integrals(all_X_int, all_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}all_integrals.pdf\")\n",
    "\n",
    "    if len(low_y_int) > 0:\n",
    "        plot_integrals(low_X_int, low_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}low_integrals.pdf\")\n",
    "\n",
    "    if len(high_y_int) > 0:\n",
    "        plot_integrals(high_X_int, high_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}high_integrals.pdf\")\n",
    "\n",
    "    if len(rand_y_int) > 0:\n",
    "        plot_integrals(rand_X_int, rand_y_int, exp_compounds, int_regions, show=False, save=f\"{fdir}rand_integrals.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f1545-5df2-4e57-bb4a-0e581f1ee7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
